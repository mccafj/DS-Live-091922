{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-93e35ef07b6a9f79",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Phase 4 Code Challenge\n",
    "\n",
    "This code challenge is designed to test your understanding of the Phase 4 material. It covers:\n",
    "\n",
    "* Principal Component Analysis\n",
    "* Clustering\n",
    "* Time Series\n",
    "* Natural Language Processing\n",
    "\n",
    "_Read the instructions carefully_. You will be asked both to write code and to answer short answer questions.\n",
    "\n",
    "## Code Tests\n",
    "\n",
    "We have provided some code tests for you to run to check that your work meets the item specifications. Passing these tests does not necessarily mean that you have gotten the item correct - there are additional hidden tests. However, if any of the tests do not pass, this tells you that your code is incorrect and needs changes to meet the specification. To determine what the issue is, read the comments in the code test cells, the error message you receive, and the item instructions.\n",
    "\n",
    "## Short Answer Questions \n",
    "\n",
    "For the short answer questions...\n",
    "\n",
    "* _Use your own words_. It is OK to refer to outside resources when crafting your response, but _do not copy text from another source_.\n",
    "\n",
    "* _Communicate clearly_. We are not grading your writing skills, but you can only receive full credit if your teacher is able to fully understand your response. \n",
    "\n",
    "* _Be concise_. You should be able to answer most short answer questions in a sentence or two. Writing unnecessarily long answers increases the risk of you being unclear or saying something incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8324b5fef3a46de1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell without changes to import the necessary libraries\n",
    "\n",
    "from numbers import Number\n",
    "import matplotlib, sklearn, scipy, pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0312e6ab3947bffa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Part 1: Principal Component Analysis [Suggested Time: 15 minutes]\n",
    "\n",
    "---\n",
    "\n",
    "In this part, you will use Principal Component Analysis on the wine dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1c655cf7834874d7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "\n",
    "# Relevant imports\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Load data\n",
    "wine = load_wine()\n",
    "X, y = load_wine(return_X_y=True)\n",
    "X = pd.DataFrame(X, columns=wine.feature_names)\n",
    "y = pd.Series(y)\n",
    "y.name = 'class'\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "# Scaling\n",
    "scaler_1 = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler_1.fit_transform(X_train), columns=X_train.columns)\n",
    "\n",
    "# Inspect the first five rows of the scaled dataset\n",
    "X_train_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-adac39f3ffb2589c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.1) Create a PCA object `wine_pca` and fit it using `X_train_scaled`.\n",
    "\n",
    "Use parameter defaults with `n_components=0.9` and `random_state=1` for your classifier. You must use the Scikit-learn PCA (docs [here](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fc96080dfc176b32",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CodeGrade step1.1\n",
    "# Your code here\n",
    "\n",
    "wine_pca = None\n",
    "\n",
    "# Fit\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This test confirms that you have created a PCA object named wine_pca\n",
    "\n",
    "assert type(wine_pca) == PCA\n",
    "\n",
    "# This test confirms that you have set random_state to 1\n",
    "\n",
    "assert wine_pca.get_params()['random_state'] == 1\n",
    "\n",
    "# This test confirms that wine_pca has been fit\n",
    "\n",
    "sklearn.utils.validation.check_is_fitted(wine_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-afa7eb5b2df5dc78",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.2) Create a numeric variable `wine_pca_ncomps` containing the number of components in `wine_pca`\n",
    "\n",
    "_Hint: Look at the list of attributes of trained `PCA` objects in the [scikit-learn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0dc95483da95ec65",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CodeGrade step1.2\n",
    "# Replace None with appropriate code\n",
    "\n",
    "wine_pca_ncomps = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This test confirms that you have created a numeric variable named wine_pca_ncomps\n",
    "\n",
    "assert isinstance(wine_pca_ncomps, Number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9db04f9af71bb32f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.3) Short Answer: Is PCA more useful or less useful when you have high multicollinearity among your features? Explain why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2be033309999869a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "--- \n",
    "\n",
    "## Part 2: Clustering [Suggested Time: 20 minutes]\n",
    "\n",
    "---\n",
    "\n",
    "In this part, you will answer general questions about clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7fb56c6a144a1ff1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f5977bb7be24f780",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2.1) Short Answer: Describe the steps of the k-means clustering algorithm.\n",
    "\n",
    "Hint: Refer to the animation below, which visualizes the process.\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/learn-co-curriculum/dsc-cc-images/main/phase_4/centroid.gif'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0d929a59f2b64837",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2.2) Write a function `get_labels()` that meets the requirements below to find `k` clusters in a dataset of features `X`, and return the cluster assignment labels for each row of `X`. \n",
    "\n",
    "Review the doc-string in the function below to understand the requirements of this function.\n",
    "\n",
    "_Hint: Within the function, you'll need to:_\n",
    "* instantiate a [scikit-learn KMeans object](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html), using `random_state = 1` for reproducibility\n",
    "* fit the object to the data\n",
    "* return the cluster assignment labels for each row of `X` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7d131ed1c76ccc52",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CodeGrade step2.2\n",
    "# Replace None with appropriate code\n",
    "\n",
    "def get_labels(k, X):\n",
    "    \"\"\" \n",
    "    Finds the labels from a k-means clustering model \n",
    "\n",
    "    Parameters: \n",
    "    -----------\n",
    "    k: float object\n",
    "        number of clusters to use in the k-means clustering model\n",
    "    X: Pandas DataFrame or array-like object\n",
    "        Data to cluster\n",
    "\n",
    "    Returns: \n",
    "    --------\n",
    "    labels: array-like object\n",
    "        Labels attribute from the k-means model\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Instantiate a k-means clustering model with random_state=1 and n_clusters=k\n",
    "    kmeans = None\n",
    "\n",
    "    # Fit the model to the data\n",
    "    None\n",
    "\n",
    "    # Return the predicted labels for each row in the data produced by the model\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This test confirms that you have created a function named get_labels\n",
    "\n",
    "assert callable(get_labels) \n",
    "\n",
    "# This test confirms that get_labels can take the correct parameter types\n",
    "\n",
    "get_labels(1, np.array([[1, 2, 3], [2, 3, 4], [3, 4, 5]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3e44a061e098167b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The next cell uses your `get_labels` function to cluster the wine data, looping through all $k$ values from 2 to 9. It saves the silhouette scores for each $k$ value in a list `silhouette_scores`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e668bf9ba032a378",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Preprocessing is needed. Scale the data\n",
    "scaler_2 = StandardScaler()\n",
    "X_scaled = scaler_2.fit_transform(X)\n",
    "\n",
    "# Create empty list for silhouette scores\n",
    "silhouette_scores = []\n",
    "\n",
    "# Range of k values to try\n",
    "k_values = range(2, 10)\n",
    "\n",
    "for k in k_values:\n",
    "    labels = get_labels(k, X_scaled)\n",
    "    score = silhouette_score(X_scaled, labels, metric='euclidean')\n",
    "    silhouette_scores.append(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-38e582c973d5e62e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Next, we plot the silhouette scores obtained for each different value of $k$, against $k$, the number of clusters we asked the algorithm to find. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-89d3669094b3d4e0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(k_values, silhouette_scores, marker='o')\n",
    "plt.title('Silhouette scores vs number of clusters')\n",
    "plt.xlabel('k (number of clusters)')\n",
    "plt.ylabel('silhouette score');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-74ff2d4b4db6f745",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2.3) Create numeric variable `wine_nclust` containing the value of $k$ you would choose based on the above plot of silhouette scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3d86a102cb0b9d05",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CodeGrade step2.3\n",
    "# Replace None with appropriate code\n",
    "\n",
    "wine_nclust = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This test confirms that you have created a numeric variable named wine_nclust\n",
    "\n",
    "assert isinstance(wine_nclust, Number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b70729833605d576",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Part 3: Natural Language Processing [Suggested Time: 20 minutes]\n",
    "\n",
    "---\n",
    "\n",
    "In this third section we will attempt to classify text messages as \"SPAM\" or \"HAM\" using TF-IDF Vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2bcac79fa0ec69f4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "\n",
    "# Import necessary libraries \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# Generate a list of stopwords \n",
    "nltk.download('stopwords')\n",
    "stops = stopwords.words('english') + list(string.punctuation)\n",
    "\n",
    "# Read in data\n",
    "df_messages = pd.read_csv('./spam.csv', usecols=[0,1])\n",
    "\n",
    "# Convert string labels to 1 or 0 \n",
    "le = LabelEncoder()\n",
    "df_messages['target'] = le.fit_transform(df_messages['v1'])\n",
    "\n",
    "# Examine our data\n",
    "print(df_messages.head())\n",
    "\n",
    "# Separate features and labels \n",
    "X = df_messages['v2']\n",
    "y = df_messages['target']\n",
    "\n",
    "# Create test and train datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fdb9d8950abce1f2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 3.1) Create CSR matrices `tf_idf_train` and `tf_idf_test` by using a `TfidfVectorizer` with stop word list `stops` to vectorize `X_train` and `X_test`, respectively.\n",
    "\n",
    "Besides using the stop word list, use paramater defaults for your TfidfVectorizer. Refer to the documentation about [TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-01f4a0cd5f6b22f8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CodeGrade step3.1\n",
    "# Replace None with appropriate code\n",
    "\n",
    "vectorizer = None\n",
    "\n",
    "tf_idf_train = None\n",
    "\n",
    "tf_idf_test = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These tests confirm that you have created CSR matrices tf_idf_train and tf_idf_test\n",
    "\n",
    "assert type(tf_idf_train) == scipy.sparse.csr.csr_matrix\n",
    "assert type(tf_idf_test) == scipy.sparse.csr.csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4c0469e57522c867",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 3.2) Create an array `y_preds` containing predictions from an untuned `RandomForestClassifier` that uses `tf_idf_train` and `tf_idf_test`.\n",
    "\n",
    "Use parameter defaults with `random_state=1` for your classifier. Refer to the documentation on [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8b45b5691fce29ee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CodeGrade step3.2\n",
    "# Replace None with appropriate code\n",
    "\n",
    "classifier = None\n",
    "\n",
    "#Fit on training\n",
    "None\n",
    "\n",
    "\n",
    "# Predict using test    \n",
    "y_preds = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This test confirms that you have created an array named y_preds\n",
    "\n",
    "assert type(y_preds) == np.ndarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-18c4bf3c4e9875a2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 3.3) Short Answer: What would it mean if the word \"genuine\" had the highest TF-IDF value of all words in one document from our test data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f190415dece92737",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Part 4: Time Series [Suggested Time: 20 minutes]\n",
    "\n",
    "---\n",
    "In this part you will analyze the price of one stock over time. Each row of the dataset has four prices tracked for each day: \n",
    "\n",
    "* Open: The price when the market opens.\n",
    "* High: The highest price over the course of the day.\n",
    "* Low: The lowest price over the course of the day.\n",
    "* Close: The price when the market closes.\n",
    "\n",
    "<!---Create stock_df and save as .pkl\n",
    "stocks_df = pd.read_csv(\"raw_data/all_stocks_5yr.csv\")\n",
    "stocks_df[\"clean_date\"] = pd.to_datetime(stocks_df[\"date\"], format=\"%Y-%m-%d\")\n",
    "stocks_df.drop([\"date\", \"clean_date\", \"volume\", \"Name\"], axis=1, inplace=True)\n",
    "stocks_df.rename(columns={\"string_date\": \"date\"}, inplace=True)\n",
    "pickle.dump(stocks_df, open(\"write_data/all_stocks_5yr.pkl\", \"wb\"))\n",
    "--->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fd9493a8ea890a36",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "\n",
    "stocks_df = pd.read_csv('./stocks_5yr.csv')\n",
    "stocks_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f6bc3b15110435d3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 4.1) For `stocks_df`, create a DatetimeIndex from the `date` column.\n",
    "\n",
    "The resulting DataFrame should not have a `date` column, only `open`, `high`, `low`, and `close` columns. \n",
    "\n",
    "Hint: First convert the `date` column to Datetime datatype, then set it as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-15921f7c4cf5e767",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CodeGrade step4.1\n",
    "# Replace None with appropriate code\n",
    "\n",
    "stocks_df['date'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This test confirms that stocks_df has a DatetimeIndex\n",
    "\n",
    "assert type(stocks_df.index) == pd.core.indexes.datetimes.DatetimeIndex\n",
    "\n",
    "# This test confirms that stocks_df only has `open`, `high`, `low`, and `close` columns.\n",
    "\n",
    "assert list(stocks_df.columns) == ['open', 'high', 'low', 'close']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-56237f4da08165ef",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 4.2) Create a DataFrame `stocks_monthly_df` that resamples `stocks_df` each month with the 'MS' DateOffset to calculate the mean of the four features over each month.\n",
    "\n",
    "Refer to the [resample documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.resample.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-24dbe2526545b9bb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CodeGrade step4.2\n",
    "# Replace None with appropriate code\n",
    "\n",
    "stocks_monthly_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This test confirms that you have created a DataFrame named stocks_monthly_df\n",
    "\n",
    "assert type(stocks_monthly_df) == pd.DataFrame\n",
    "\n",
    "# This test confirms that stocks_monthy_df has the correct dimensions\n",
    "\n",
    "assert stocks_monthly_df.shape == (61, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a33f13a6897659d2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 4.3) Create a matplotlib figure `rolling_open_figure` containing a line graph that visualizes the rolling quarterly mean of open prices from `stocks_monthly_df`.\n",
    "\n",
    "You will use this graph to determine whether the average monthly open stock price is stationary or not.\n",
    "\n",
    "Hint: use a window size of 3 to represent one quarter of a year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-60d8542e250c354f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CodeGrade step4.3\n",
    "# Your code here\n",
    "# Create rolling mean with window 3 for the open column\n",
    "roll_mean = \n",
    "\n",
    "rolling_open_figure, ax = plt.subplots(figsize=(10, 6))\n",
    "#Plot\n",
    "ax.plot(None)\n",
    "ax.legend()\n",
    "plt.title('Average Monthly Open Stock Prices (Feb 2013 - Feb 2018)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This test confirms that you have created a figure named rolling_open_figure\n",
    "\n",
    "assert type(rolling_open_figure) == plt.Figure\n",
    "\n",
    "# This test confirms that the figure contains exactly one axis\n",
    "\n",
    "assert len(rolling_open_figure.axes) == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0aef1dacb1d8361f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 4.4) Short Answer: Based on your graph from Question 4.3, does the monthly open stock price look stationary? Explain your answer, what statistical test could you use to determine?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
